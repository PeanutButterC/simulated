{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.append('../scripts')\n",
    "from paths import SIMULATED_PATH, SIMULATED_DATA_ROOT\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_data = tf.keras.datasets.mnist.load_data()\n",
    "x = {\n",
    "    'train': mnist_data[0][0],\n",
    "    'test': mnist_data[1][0]\n",
    "}\n",
    "y = {\n",
    "    'train': mnist_data[0][1],\n",
    "    'test': mnist_data[1][1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(data):\n",
    "    fig, ax = plt.subplots(3, 3, figsize=(8, 8))\n",
    "    for i in range(9):\n",
    "        ax[i // 3, i % 3].imshow(data[i])\n",
    "        ax[i // 3, i % 3].set_xticks([])\n",
    "        ax[i // 3, i % 3].set_yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(x['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate linear classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/999\n",
      "938/938 [==============================] - 6s 4ms/step - loss: 8.0353 - accuracy: 0.8144 - val_loss: 0.5631 - val_accuracy: 0.8903\n",
      "Epoch 2/999\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.4155 - accuracy: 0.9110 - val_loss: 0.4042 - val_accuracy: 0.9178\n",
      "Epoch 3/999\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2792 - accuracy: 0.9297 - val_loss: 0.3183 - val_accuracy: 0.9328\n",
      "Epoch 4/999\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2186 - accuracy: 0.9425 - val_loss: 0.2776 - val_accuracy: 0.9354\n",
      "Epoch 5/999\n",
      "938/938 [==============================] - 4s 4ms/step - loss: 0.2085 - accuracy: 0.9454 - val_loss: 0.2885 - val_accuracy: 0.9459\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x255bdd26df0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(verbose=1)\n",
    "]\n",
    "classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.fit(x['train'], y['train'], validation_data=(x['test'], y['test']), epochs=999, batch_size=64, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "temperature = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1 / 255.),\n",
    "    tf.keras.layers.experimental.preprocessing.RandomRotation(.1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_aug = {}\n",
    "batch_size = 256\n",
    "for type in ['train', 'test']:\n",
    "    x_aug[type] = []\n",
    "    for i in range(0, x[type].shape[0] - batch_size + 1, batch_size):\n",
    "        x_batch = x[type][i:i+batch_size]\n",
    "        x_batch = tf.repeat(x_batch[:, :, :, tf.newaxis], 3, axis=-1)\n",
    "        x_batch_a = data_augmentation(x_batch)\n",
    "        x_batch_b = data_augmentation(x_batch)\n",
    "        x_batch_aug = tf.concat([x_batch_a, x_batch_b], axis=0)\n",
    "        x_aug[type].append(x_batch_aug)\n",
    "    x_aug[type] = tf.convert_to_tensor(x_aug[type], dtype=tf.float32)\n",
    "fig, ax = plt.subplots(2, 2)\n",
    "ax[0, 0].imshow(x_aug['train'][0, 0])\n",
    "ax[0, 1].imshow(x_aug['train'][0, batch_size])\n",
    "ax[1, 0].imshow(x_aug['train'][0, 1])\n",
    "ax[1, 1].imshow(x_aug['train'][0, batch_size + 1])\n",
    "for i in range(4):\n",
    "    ax[i // 2, i % 2].set_xticks([])\n",
    "    ax[i // 2, i % 2].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        '''self.encoder = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            tf.keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "            tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dropout(.5),\n",
    "            tf.keras.layers.Dense(128, activation='relu')\n",
    "        ])'''\n",
    "        self.encoder = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(128, activation='relu')\n",
    "        ])\n",
    "        self.training_head = tf.keras.layers.Dense(128)\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.training_head(x)\n",
    "        z_i, z_j = tf.split(x, 2, axis=0)\n",
    "        return z_i, z_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(z_i, z_j, temperature=1.0):\n",
    "    batch_size = tf.shape(z_i)[0]\n",
    "    labels = tf.one_hot(tf.range(batch_size), batch_size * 2)\n",
    "    mask = tf.one_hot(tf.range(batch_size), batch_size)\n",
    "    logits_aa = tf.matmul(z_i, z_i, transpose_b=True) / temperature\n",
    "    logits_aa -= mask * 1e9\n",
    "    logits_bb = tf.matmul(z_j, z_j, transpose_b=True) / temperature\n",
    "    logits_bb -= mask * 1e9\n",
    "    logits_ab = tf.matmul(z_i, z_j, transpose_b=True) / temperature\n",
    "    logits_ba = tf.matmul(z_j, z_i, transpose_b=True) / temperature\n",
    "    loss_a = tf.nn.softmax_cross_entropy_with_logits(labels, tf.concat([logits_ab, logits_aa], 1))\n",
    "    loss_b = tf.nn.softmax_cross_entropy_with_logits(labels, tf.concat([logits_ba, logits_bb], 1))\n",
    "    loss = tf.reduce_mean(loss_a + loss_b)\n",
    "    return loss, logits_ab, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 4.514532566070557 Test loss: 1.60652494430542\n",
      "Improved\n",
      "Train loss: 0.94931960105896 Test loss: 0.6916796565055847\n",
      "Improved\n",
      "Train loss: 0.4088791310787201 Test loss: 0.38086003065109253\n",
      "Improved\n",
      "Train loss: 0.23442889750003815 Test loss: 0.26989519596099854\n",
      "Improved\n",
      "Train loss: 0.16988380253314972 Test loss: 0.22995053231716156\n",
      "Improved\n",
      "Train loss: 0.14121492207050323 Test loss: 0.2319725751876831\n",
      "Train loss: 0.13060423731803894 Test loss: 0.20734676718711853\n",
      "Improved\n",
      "Train loss: 0.1314667910337448 Test loss: 0.23689042031764984\n",
      "Train loss: 0.12216880172491074 Test loss: 0.20314200222492218\n",
      "Improved\n",
      "Train loss: 0.14969658851623535 Test loss: 0.21390677988529205\n",
      "Train loss: 0.12866586446762085 Test loss: 0.21022586524486542\n",
      "Train loss: 0.11874403059482574 Test loss: 0.24092476069927216\n",
      "Train loss: 0.12700170278549194 Test loss: 0.19103263318538666\n",
      "Improved\n",
      "Train loss: 0.10388112813234329 Test loss: 0.14357230067253113\n",
      "Improved\n",
      "Train loss: 0.12949901819229126 Test loss: 0.187498539686203\n",
      "Train loss: 0.1431359052658081 Test loss: 0.16541312634944916\n",
      "Train loss: 0.1182958111166954 Test loss: 0.1444859355688095\n",
      "Train loss: 0.09785062819719315 Test loss: 0.12300726026296616\n",
      "Improved\n",
      "Train loss: 0.06952938437461853 Test loss: 0.11399499326944351\n",
      "Improved\n",
      "Train loss: 0.12017873674631119 Test loss: 0.1729857176542282\n",
      "Train loss: 0.08779357373714447 Test loss: 0.14770300686359406\n",
      "Train loss: 0.08638428151607513 Test loss: 0.13625065982341766\n",
      "Train loss: 0.0839361697435379 Test loss: 0.12458888441324234\n",
      "Train loss: 0.09102778136730194 Test loss: 0.12630595266819\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "temperature = .1\n",
    "model = ContrastiveModel()\n",
    "best_test_loss = float('inf')\n",
    "k = 0\n",
    "for epoch in range(999):\n",
    "    train_loss_avg = tf.keras.metrics.Mean()\n",
    "    test_loss_avg = tf.keras.metrics.Mean()\n",
    "    for batch in x_aug['train']:\n",
    "        with tf.GradientTape() as tape:\n",
    "            z_i, z_j = model(batch)\n",
    "            loss, _, _ = contrastive_loss(z_i, z_j, temperature=temperature)\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "            train_loss_avg.update_state(loss)\n",
    "    for batch in x_aug['test']:\n",
    "        z_i, z_j = model(batch)\n",
    "        loss, _, _ = contrastive_loss(z_i, z_j, temperature=temperature)\n",
    "        test_loss_avg.update_state(loss)\n",
    "    train_loss = train_loss_avg.result()\n",
    "    test_loss = test_loss_avg.result()\n",
    "    print(f'Train loss: {train_loss} Test loss: {test_loss}')\n",
    "    if test_loss < best_test_loss:\n",
    "        k = 0\n",
    "        best_test_loss = test_loss\n",
    "        print('Improved')\n",
    "        model.save_weights('contrastive_weights.h5')\n",
    "    else:\n",
    "        k += 1\n",
    "        if k >= 5:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.11399498\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('contrastive_weights.h5')\n",
    "test_loss_avg = tf.keras.metrics.Mean()\n",
    "for batch in x_aug['test']:\n",
    "    z_i, z_j = model(batch)\n",
    "    loss, _, _ = contrastive_loss(z_i, z_j, temperature=temperature)\n",
    "    test_loss_avg.update_state(loss)\n",
    "print('Test loss: ' + str(test_loss_avg.result().numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train supervised head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveProbe(tf.keras.Model):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.model.trainable = False\n",
    "        self.supervised_head = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Dense(128, activation='relu'),\n",
    "            tf.keras.layers.Dense(10, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "    def call(self, x):\n",
    "        x = self.model.encoder(x)\n",
    "        return self.supervised_head(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = tf.keras.Sequential([\n",
    "    tf.keras.layers.experimental.preprocessing.Rescaling(1 / 255.)\n",
    "])\n",
    "\n",
    "x_probe = {}\n",
    "for type in ['train', 'test']:\n",
    "    x_probe[type] = tf.repeat(x[type][:, :, :, tf.newaxis], 3, axis=-1)\n",
    "    x_probe[type] = resize(x_probe[type])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/999\n",
      "235/235 [==============================] - 2s 5ms/step - loss: 1.4192 - accuracy: 0.5480 - val_loss: 0.7362 - val_accuracy: 0.7647\n",
      "Epoch 2/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.7086 - accuracy: 0.7748 - val_loss: 0.6339 - val_accuracy: 0.7957\n",
      "Epoch 3/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.6279 - accuracy: 0.7965 - val_loss: 0.5930 - val_accuracy: 0.8083\n",
      "Epoch 4/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.5843 - accuracy: 0.8093 - val_loss: 0.5653 - val_accuracy: 0.8156\n",
      "Epoch 5/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.5518 - accuracy: 0.8195 - val_loss: 0.5430 - val_accuracy: 0.8238\n",
      "Epoch 6/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5260 - accuracy: 0.8266 - val_loss: 0.5320 - val_accuracy: 0.8255\n",
      "Epoch 7/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5168 - accuracy: 0.8309 - val_loss: 0.5166 - val_accuracy: 0.8305\n",
      "Epoch 8/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4955 - accuracy: 0.8375 - val_loss: 0.5076 - val_accuracy: 0.8328\n",
      "Epoch 9/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4871 - accuracy: 0.8403 - val_loss: 0.4983 - val_accuracy: 0.8381\n",
      "Epoch 10/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4729 - accuracy: 0.8460 - val_loss: 0.4910 - val_accuracy: 0.8396\n",
      "Epoch 11/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4713 - accuracy: 0.8450 - val_loss: 0.4828 - val_accuracy: 0.8431\n",
      "Epoch 12/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4539 - accuracy: 0.8503 - val_loss: 0.4758 - val_accuracy: 0.8452\n",
      "Epoch 13/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4517 - accuracy: 0.8495 - val_loss: 0.4720 - val_accuracy: 0.8458\n",
      "Epoch 14/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4424 - accuracy: 0.8533 - val_loss: 0.4673 - val_accuracy: 0.8481\n",
      "Epoch 15/999\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4362 - accuracy: 0.8561 - val_loss: 0.4625 - val_accuracy: 0.8494\n",
      "Epoch 16/999\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.8577 - val_loss: 0.4595 - val_accuracy: 0.8499\n",
      "Epoch 17/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4188 - accuracy: 0.8617 - val_loss: 0.4509 - val_accuracy: 0.8529\n",
      "Epoch 18/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4105 - accuracy: 0.8655 - val_loss: 0.4550 - val_accuracy: 0.8499\n",
      "Epoch 19/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4154 - accuracy: 0.8612 - val_loss: 0.4488 - val_accuracy: 0.8542\n",
      "Epoch 20/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4077 - accuracy: 0.8654 - val_loss: 0.4434 - val_accuracy: 0.8558\n",
      "Epoch 21/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3991 - accuracy: 0.8708 - val_loss: 0.4370 - val_accuracy: 0.8567\n",
      "Epoch 22/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4029 - accuracy: 0.8679 - val_loss: 0.4367 - val_accuracy: 0.8578\n",
      "Epoch 23/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3895 - accuracy: 0.8728 - val_loss: 0.4306 - val_accuracy: 0.8596\n",
      "Epoch 24/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3813 - accuracy: 0.8753 - val_loss: 0.4297 - val_accuracy: 0.8593\n",
      "Epoch 25/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3783 - accuracy: 0.8746 - val_loss: 0.4309 - val_accuracy: 0.8607\n",
      "Epoch 26/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3733 - accuracy: 0.8761 - val_loss: 0.4240 - val_accuracy: 0.8628\n",
      "Epoch 27/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3781 - accuracy: 0.8756 - val_loss: 0.4247 - val_accuracy: 0.8621\n",
      "Epoch 28/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3741 - accuracy: 0.8752 - val_loss: 0.4263 - val_accuracy: 0.8613\n",
      "Epoch 29/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3626 - accuracy: 0.8797 - val_loss: 0.4217 - val_accuracy: 0.8614\n",
      "Epoch 30/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3615 - accuracy: 0.8811 - val_loss: 0.4172 - val_accuracy: 0.8621\n",
      "Epoch 31/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3611 - accuracy: 0.8808 - val_loss: 0.4154 - val_accuracy: 0.8635\n",
      "Epoch 32/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3554 - accuracy: 0.8834 - val_loss: 0.4212 - val_accuracy: 0.8612\n",
      "Epoch 33/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3546 - accuracy: 0.8816 - val_loss: 0.4139 - val_accuracy: 0.8657\n",
      "Epoch 34/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3513 - accuracy: 0.8833 - val_loss: 0.4149 - val_accuracy: 0.8657\n",
      "Epoch 35/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3446 - accuracy: 0.8845 - val_loss: 0.4102 - val_accuracy: 0.8656\n",
      "Epoch 36/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3445 - accuracy: 0.8848 - val_loss: 0.4106 - val_accuracy: 0.8651\n",
      "Epoch 37/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3356 - accuracy: 0.8883 - val_loss: 0.4078 - val_accuracy: 0.8648\n",
      "Epoch 38/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3328 - accuracy: 0.8881 - val_loss: 0.4124 - val_accuracy: 0.8674\n",
      "Epoch 39/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3394 - accuracy: 0.8865 - val_loss: 0.4073 - val_accuracy: 0.8672\n",
      "Epoch 40/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3332 - accuracy: 0.8900 - val_loss: 0.4021 - val_accuracy: 0.8701\n",
      "Epoch 41/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3264 - accuracy: 0.8929 - val_loss: 0.4048 - val_accuracy: 0.8684\n",
      "Epoch 42/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3266 - accuracy: 0.8914 - val_loss: 0.4001 - val_accuracy: 0.8701\n",
      "Epoch 43/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3267 - accuracy: 0.8919 - val_loss: 0.4038 - val_accuracy: 0.8693\n",
      "Epoch 44/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3231 - accuracy: 0.8929 - val_loss: 0.4017 - val_accuracy: 0.8703\n",
      "Epoch 45/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3191 - accuracy: 0.8927 - val_loss: 0.4019 - val_accuracy: 0.8710\n",
      "Epoch 46/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3234 - accuracy: 0.8913 - val_loss: 0.4009 - val_accuracy: 0.8703\n",
      "Epoch 47/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3146 - accuracy: 0.8949 - val_loss: 0.4086 - val_accuracy: 0.8686\n",
      "Epoch 00047: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257e4719e50>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervised = ContrastiveProbe(model)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(verbose=1, patience=5),\n",
    "    tf.keras.callbacks.ModelCheckpoint('contrastive_probe.h5', save_best_only=True)\n",
    "]\n",
    "supervised.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "supervised.fit(x_probe['train'], y['train'], validation_data=(x_probe['test'], y['test']), batch_size=batch_size, epochs=999, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4001 - accuracy: 0.8701\n",
      "Accuracy: 0.870\n"
     ]
    }
   ],
   "source": [
    "supervised.load_weights('contrastive_probe.h5')\n",
    "loss, acc = supervised.evaluate(x_probe['test'], y['test'])\n",
    "print(f'Accuracy: {acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also try randomly initialized encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/999\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 1.4620 - accuracy: 0.5356 - val_loss: 0.7432 - val_accuracy: 0.7658\n",
      "Epoch 2/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.7252 - accuracy: 0.7692 - val_loss: 0.6371 - val_accuracy: 0.7980\n",
      "Epoch 3/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.6363 - accuracy: 0.7936 - val_loss: 0.5962 - val_accuracy: 0.8064\n",
      "Epoch 4/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5845 - accuracy: 0.8107 - val_loss: 0.5704 - val_accuracy: 0.8149\n",
      "Epoch 5/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5632 - accuracy: 0.8162 - val_loss: 0.5488 - val_accuracy: 0.8204\n",
      "Epoch 6/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.5341 - accuracy: 0.8231 - val_loss: 0.5396 - val_accuracy: 0.8240\n",
      "Epoch 7/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.5203 - accuracy: 0.8279 - val_loss: 0.5219 - val_accuracy: 0.8285\n",
      "Epoch 8/999\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4982 - accuracy: 0.8378 - val_loss: 0.5093 - val_accuracy: 0.8331\n",
      "Epoch 9/999\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4892 - accuracy: 0.8368 - val_loss: 0.4936 - val_accuracy: 0.8407\n",
      "Epoch 10/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.8452 - val_loss: 0.4855 - val_accuracy: 0.8415\n",
      "Epoch 11/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4601 - accuracy: 0.8470 - val_loss: 0.4822 - val_accuracy: 0.8426\n",
      "Epoch 12/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4528 - accuracy: 0.8501 - val_loss: 0.4684 - val_accuracy: 0.8461\n",
      "Epoch 13/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4489 - accuracy: 0.8518 - val_loss: 0.4633 - val_accuracy: 0.8498\n",
      "Epoch 14/999\n",
      "235/235 [==============================] - 1s 4ms/step - loss: 0.4390 - accuracy: 0.8549 - val_loss: 0.4605 - val_accuracy: 0.8520\n",
      "Epoch 15/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4254 - accuracy: 0.8573 - val_loss: 0.4531 - val_accuracy: 0.8517\n",
      "Epoch 16/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4245 - accuracy: 0.8608 - val_loss: 0.4466 - val_accuracy: 0.8543\n",
      "Epoch 17/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.4152 - accuracy: 0.8630 - val_loss: 0.4445 - val_accuracy: 0.8530\n",
      "Epoch 18/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4139 - accuracy: 0.8639 - val_loss: 0.4397 - val_accuracy: 0.8574\n",
      "Epoch 19/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.4013 - accuracy: 0.8701 - val_loss: 0.4374 - val_accuracy: 0.8575\n",
      "Epoch 20/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3931 - accuracy: 0.8709 - val_loss: 0.4335 - val_accuracy: 0.8585\n",
      "Epoch 21/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3815 - accuracy: 0.8736 - val_loss: 0.4348 - val_accuracy: 0.8582\n",
      "Epoch 22/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3871 - accuracy: 0.8732 - val_loss: 0.4273 - val_accuracy: 0.8604\n",
      "Epoch 23/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3735 - accuracy: 0.8787 - val_loss: 0.4255 - val_accuracy: 0.8595\n",
      "Epoch 24/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3712 - accuracy: 0.8782 - val_loss: 0.4190 - val_accuracy: 0.8625\n",
      "Epoch 25/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3722 - accuracy: 0.8765 - val_loss: 0.4260 - val_accuracy: 0.8610\n",
      "Epoch 26/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3670 - accuracy: 0.8795 - val_loss: 0.4153 - val_accuracy: 0.8645\n",
      "Epoch 27/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3650 - accuracy: 0.8799 - val_loss: 0.4161 - val_accuracy: 0.8637\n",
      "Epoch 28/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3605 - accuracy: 0.8814 - val_loss: 0.4150 - val_accuracy: 0.8630\n",
      "Epoch 29/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3579 - accuracy: 0.8823 - val_loss: 0.4113 - val_accuracy: 0.8650\n",
      "Epoch 30/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3511 - accuracy: 0.8841 - val_loss: 0.4087 - val_accuracy: 0.8676\n",
      "Epoch 31/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3523 - accuracy: 0.8842 - val_loss: 0.4071 - val_accuracy: 0.8674\n",
      "Epoch 32/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3475 - accuracy: 0.8856 - val_loss: 0.4070 - val_accuracy: 0.8669\n",
      "Epoch 33/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3451 - accuracy: 0.8866 - val_loss: 0.4087 - val_accuracy: 0.8663\n",
      "Epoch 34/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3383 - accuracy: 0.8882 - val_loss: 0.4026 - val_accuracy: 0.8684\n",
      "Epoch 35/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3372 - accuracy: 0.8894 - val_loss: 0.3984 - val_accuracy: 0.8722\n",
      "Epoch 36/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3300 - accuracy: 0.8913 - val_loss: 0.4030 - val_accuracy: 0.8684\n",
      "Epoch 37/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3334 - accuracy: 0.8896 - val_loss: 0.4055 - val_accuracy: 0.8677\n",
      "Epoch 38/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.3294 - accuracy: 0.8920 - val_loss: 0.3997 - val_accuracy: 0.8704\n",
      "Epoch 39/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3232 - accuracy: 0.8935 - val_loss: 0.4039 - val_accuracy: 0.8661\n",
      "Epoch 40/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.3243 - accuracy: 0.8925 - val_loss: 0.4049 - val_accuracy: 0.8667\n",
      "Epoch 00040: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257fb2a1ac0>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "import tensorflow.keras.backend as K\n",
    "rand_model = ContrastiveModel()\n",
    "rand_model(x_probe['train'][0])\n",
    "initial_weights = rand_model.get_weights()\n",
    "new_weights = [glorot_uniform()(w.shape) for w in initial_weights]\n",
    "rand_model.set_weights(new_weights)\n",
    "rand_probe = ContrastiveProbe(model)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(verbose=1, patience=5),\n",
    "    tf.keras.callbacks.ModelCheckpoint('contrastive_probe_randomly_initialized.h5', save_best_only=True)\n",
    "]\n",
    "rand_probe.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "rand_probe.fit(x_probe['train'], y['train'], validation_data=(x_probe['test'], y['test']), batch_size=batch_size, epochs=999, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3984 - accuracy: 0.8722\n",
      "Accuracy: 0.872\n"
     ]
    }
   ],
   "source": [
    "rand_probe.load_weights('contrastive_probe_randomly_initialized.h5')\n",
    "loss, acc = rand_probe.evaluate(x_probe['test'], y['test'])\n",
    "print(f'Accuracy: {acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also try unfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/999\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['contrastive_model_10/dense_38/kernel:0', 'contrastive_model_10/dense_38/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['contrastive_model_10/dense_38/kernel:0', 'contrastive_model_10/dense_38/bias:0'] when minimizing the loss.\n",
      "235/235 [==============================] - 2s 6ms/step - loss: 0.7873 - accuracy: 0.7413 - val_loss: 0.1483 - val_accuracy: 0.9521\n",
      "Epoch 2/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.1419 - accuracy: 0.9558 - val_loss: 0.1205 - val_accuracy: 0.9623\n",
      "Epoch 3/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9719 - val_loss: 0.1016 - val_accuracy: 0.9683\n",
      "Epoch 4/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0704 - accuracy: 0.9779 - val_loss: 0.1010 - val_accuracy: 0.9697\n",
      "Epoch 5/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0544 - accuracy: 0.9827 - val_loss: 0.0937 - val_accuracy: 0.9708\n",
      "Epoch 6/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0452 - accuracy: 0.9857 - val_loss: 0.0828 - val_accuracy: 0.9746\n",
      "Epoch 7/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0359 - accuracy: 0.9888 - val_loss: 0.0877 - val_accuracy: 0.9734\n",
      "Epoch 8/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9916 - val_loss: 0.0820 - val_accuracy: 0.9759\n",
      "Epoch 9/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0228 - accuracy: 0.9930 - val_loss: 0.0883 - val_accuracy: 0.9746\n",
      "Epoch 10/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0204 - accuracy: 0.9936 - val_loss: 0.0909 - val_accuracy: 0.9752\n",
      "Epoch 11/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0171 - accuracy: 0.9948 - val_loss: 0.0891 - val_accuracy: 0.9760\n",
      "Epoch 12/999\n",
      "235/235 [==============================] - 1s 6ms/step - loss: 0.0190 - accuracy: 0.9939 - val_loss: 0.0910 - val_accuracy: 0.9765\n",
      "Epoch 13/999\n",
      "235/235 [==============================] - 1s 5ms/step - loss: 0.0130 - accuracy: 0.9958 - val_loss: 0.0954 - val_accuracy: 0.9758\n",
      "Epoch 00013: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x257fcdce160>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unfrozen_model = ContrastiveModel()\n",
    "unfrozen_probe = ContrastiveProbe(model)\n",
    "unfrozen_probe.model.trainable = True\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(verbose=1, patience=5),\n",
    "    tf.keras.callbacks.ModelCheckpoint('contrastive_probe_unfrozen.h5', save_best_only=True)\n",
    "]\n",
    "unfrozen_probe.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "unfrozen_probe.fit(x_probe['train'], y['train'], validation_data=(x_probe['test'], y['test']), batch_size=batch_size, epochs=999, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0202 - accuracy: 0.9932\n",
      "Accuracy: 0.993\n"
     ]
    }
   ],
   "source": [
    "unfrozen_probe.load_weights('contrastive_probe_unfrozen.h5')\n",
    "loss, acc = unfrozen_probe.evaluate(x_probe['test'], y['test'])\n",
    "print(f'Accuracy: {acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
